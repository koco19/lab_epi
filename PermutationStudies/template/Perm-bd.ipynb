{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antibody levels buildings with fixed households\n",
    "\n",
    "Check whether antibody levels in a building are more similar than one would expect statistically, if people still stay in the same household.\n",
    "\n",
    "Here, we implement an approximate permutation by only permuting households of the same size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from copy import deepcopy\n",
    "import multiprocessing as mp\n",
    "from jabbar import jabbar\n",
    "from pyprojroot import here\n",
    "import os\n",
    "\n",
    "import sys\n",
    "base_path = str(here(\"\", project_files=[\".here\"]))\n",
    "perm_path = os.path.join(base_path, \"PermutationStudies\")\n",
    "if perm_path not in sys.path:\n",
    "    sys.path.insert(0, perm_path)\n",
    "from src.functions import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# old or new cutoff\n",
    "cutoff = '%%cutoff%%'\n",
    "# control variable of interest\n",
    "var = 'address_id'\n",
    "# measurements to study\n",
    "data_key = '%%data_key%%'\n",
    "# number of permutations\n",
    "n_perm = %%n_perm%%\n",
    "\n",
    "# identifier\n",
    "id_ = f\"bd_{cutoff}_{data_key}_{n_perm}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blab = read_blab(base_path)\n",
    "\n",
    "geo = read_geo(base_path)\n",
    "\n",
    "# restrict to study households\n",
    "geo = geo[geo.hht_ID.isin(blab.hh_id.unique())]\n",
    "\n",
    "# merge\n",
    "geo = geo.rename(columns={'hht_ID': 'hh_id'})\n",
    "data = pd.merge(blab, geo)\n",
    "print(blab.shape, geo.shape, data.shape, \"initially\")\n",
    "\n",
    "# remove duplicate columns\n",
    "data = data.drop_duplicates(subset=['ind_id'], keep='first')\n",
    "print(data.shape, \"after remove duplicates\")\n",
    "\n",
    "# remove nans   \n",
    "data = data[data[data_key + '_quant'].notnull()]\n",
    "print(data.shape, \"after remove nans\")\n",
    "\n",
    "# to categorical\n",
    "if cutoff == \"cutold\":\n",
    "    cutoffs = get_old_cutoffs()\n",
    "elif cutoff == \"cutnew\":\n",
    "    cutoffs = get_new_cutoffs(base_path)\n",
    "data[data_key + '_quant'] = (data[data_key + '_quant'] >= cutoffs[data_key]).astype(float)\n",
    "\n",
    "# data plot\n",
    "fig, ax = plt.subplots(figsize=(3, 3))\n",
    "ax.hist(data[data_key + '_quant'], color='C0', bins=100)\n",
    "ax.set_xlabel(data_key)\n",
    "ax.set_ylabel(\"Frequency\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to numpy for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_arr = get_data_arr(data, data_key)\n",
    "var_ids, var_ids_uq, var_id_matrix, var_sizes = get_var_id_stuff(data, var)\n",
    "data_matrix = create_data_matrix(data_arr, var_id_matrix)\n",
    "# control\n",
    "print(data_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(var_sizes, bins=np.arange(var_sizes.max()+1)+1, align='left')\n",
    "plt.title(\"Building size distribution\")\n",
    "plt.xlabel(\"Building size [participants]\")\n",
    "plt.ylabel(\"Number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Household aware permutation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "hh_ids = np.array(data.hh_id)\n",
    "hh_ids_uq = np.array(data.hh_id.unique())\n",
    "\n",
    "# list of array of indices belonging to the same household\n",
    "ixs_by_hh = [np.where(hh_ids == hh_id)[0] for hh_id in hh_ids_uq]\n",
    "\n",
    "# sort by size\n",
    "ixs_by_hh_size = {}\n",
    "for hh_ixs in ixs_by_hh:\n",
    "    ixs_by_hh_size.setdefault(len(hh_ixs), []).append(hh_ixs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checks\n",
    "perm_ixs = permute_ixs_fix_hhs(len(hh_ids), ixs_by_hh_size)\n",
    "for hh_ixs in ixs_by_hh:\n",
    "    all_hh_ids = [hh_ids[perm_ixs[hh_ix]] for hh_ix in hh_ixs]\n",
    "    assert len(set(all_hh_ids)) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we perform a time-intensive permutation test, we need to make the computations efficient. To check validity and efficiency, below we provide implementations in pandas, numpy, and fully vectorized numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "real_mean = statistic_mean_pd(data, data_key, var, var_ids_uq)\n",
    "print(real_mean)\n",
    "real_variance = statistic_var_pd(data, data_key, var, var_ids_uq)\n",
    "print(real_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy implementation with iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "real_mean = statistic_mean_np_iter(data_arr, var_ids, var_ids_uq)\n",
    "print(real_mean)\n",
    "real_variance = statistic_var_np_iter(data_arr, var_ids, var_ids_uq)\n",
    "print(real_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Completely vectorized numpy implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_matrix_dict = create_data_matrix(data_arr, var_id_matrix)\n",
    "\n",
    "real_mean = statistic_mean(data_matrix, var_sizes)\n",
    "print(real_mean)\n",
    "real_variance = statistic_var(data_matrix, var_sizes, var_id_matrix)\n",
    "print(real_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This >30 fold speed-up should be enough for the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "# define permutations\n",
    "data_arr_perms = get_data_arr_perms_fix_hhs(\n",
    "    data_arr, n_perm, ixs_by_hh_size)\n",
    "\n",
    "# for results\n",
    "means = []\n",
    "variances = []\n",
    "\n",
    "# loop over all permutations\n",
    "for data_arr_perm in jabbar(data_arr_perms, symbols='ðŸ¦„'):\n",
    "    # get permutation\n",
    "    data_matrix = create_data_matrix(data_arr_perm, var_id_matrix)\n",
    "    # compute mean mean and mean variance\n",
    "    means.append(statistic_mean(data_matrix, var_sizes))\n",
    "    variances.append(statistic_var(data_matrix, var_sizes, var_id_matrix))\n",
    "\n",
    "# to numpy arrays\n",
    "means = np.array(means)\n",
    "variances = np.array(variances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data\n",
    "save_data(id_, means=means, variances=variances,\n",
    "          real_mean=real_mean, real_variance=real_variance,\n",
    "          perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "means, variances, real_mean, real_variance = load_data(\n",
    "    id_=id_, obj_keys=['means', 'variances', 'real_mean', 'real_variance'],\n",
    "    perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for means\n",
    "plot_kde(samples=means, obj_key='means', real_sample=real_mean,\n",
    "         data_key=data_key, id_=id_, suptitle=\"Average mean over buildings\",\n",
    "         perm_path=perm_path)\n",
    "plot_hist(samples=means, obj_key='means', real_sample=real_mean,\n",
    "          data_key=data_key, id_=id_, suptitle=\"Average mean over buildings\",\n",
    "          perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for variances\n",
    "plot_kde(samples=variances, obj_key='variances', real_sample=real_variance,\n",
    "         data_key=data_key, id_=id_, suptitle=\"Average variance over buildings\",\n",
    "         perm_path=perm_path)\n",
    "plot_hist(samples=variances, obj_key='variances', real_sample=real_variance,\n",
    "          data_key=data_key, id_=id_, suptitle=\"Average variance over buildings\",\n",
    "          perm_path=perm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentiles:\")\n",
    "print(\"Mean\", data_key, sum(means <= real_mean) / len(means))\n",
    "print(\"Variance\", data_key, sum(variances <= real_variance) / len(variances))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
